{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"dorothy_and_the_wizard_in_oz.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    corpus_text = f.read()\n",
    "\n",
    "corpus_text_length = len(corpus_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = sorted(set(corpus_text))\n",
    "vocabulary_length = len(vocabulary)\n",
    "\n",
    "# ---------------------------------------- string_to_int dictionary\n",
    "# string_to_int = {ch: i for i, ch in enumerate(chars)}\n",
    "string_to_int_dictionary = {}\n",
    "for i, c in enumerate(vocabulary):\n",
    "    string_to_int_dictionary[c] = i\n",
    "\n",
    "\n",
    "string_to_int_dictionary_length = len(string_to_int_dictionary)\n",
    "\n",
    "\n",
    "# ---------------------------------------- int_to_string dictionary\n",
    "# int_to_string = {i: ch for i, ch in enumerate(chars)}\n",
    "int_to_string_dictionary = {}\n",
    "for i, c in enumerate(vocabulary):\n",
    "    int_to_string_dictionary[i] = c\n",
    "\n",
    "\n",
    "int_to_string_dictionary_length = len(int_to_string_dictionary)\n",
    "\n",
    "# ---------------------------------------- encode string\n",
    "# encode = lambda s: [string_to_int[c] for c in s]\n",
    "def encode(string):\n",
    "    result = []\n",
    "    for c in string:\n",
    "        result.append(string_to_int_dictionary[c])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ---------------------------------------- decode int\n",
    "# decode = lambda l: ''.join([int_to_string[i] for i in l])\n",
    "def decode(int_list):\n",
    "    result = \"\"\n",
    "    for i in int_list:\n",
    "        result = result + int_to_string_dictionary[i]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"z:\\env\\python312\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"z:\\env\\python312\\Lib\\asyncio\\base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"z:\\env\\python312\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"z:\\env\\python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_10568\\2691403203.py\", line 3, in <module>\n",
      "    tensor_data = torch.tensor(encode(corpus_text), dtype=torch.long)\n",
      "C:\\Users\\anton\\AppData\\Local\\Temp\\ipykernel_10568\\2691403203.py:3: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  tensor_data = torch.tensor(encode(corpus_text), dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "import torch as torch\n",
    "\n",
    "tensor_data = torch.tensor(encode(corpus_text), dtype=torch.long)\n",
    "tensor_data_length = len(tensor_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_percentage = 0.8\n",
    "\n",
    "train_data_length = int(train_data_percentage * tensor_data_length)\n",
    "train_data = tensor_data[:train_data_length]\n",
    "\n",
    "validation_data_length = tensor_data_length - train_data_length\n",
    "validation_data = tensor_data[train_data_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Corpus =====================================\n",
      "corpus_text (first 50 chars)   => ï»¿The Project Gutenberg eBook of Dorothy and the Wi\n",
      "corpus_text_length             => 252022\n",
      "\n",
      "==================== Vocabulary & Dictionary ====================\n",
      "vocabulary (first 20) => ['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3']\n",
      "vocabulary_length     => 92\n",
      "int_to_string_dictionary_length     => 92\n",
      "string_to_int_dictionary_length     => 92\n",
      "\n",
      "==================== Tensor Data ================================\n",
      "tensor_data (first 10) => tensor([91, 48, 65, 62,  1, 44, 75, 72, 67, 62])\n",
      "tensor_data_length     => 252022\n",
      "\n",
      "train_data (percentage) => 80.0%\n",
      "train_data (first 10)   => tensor([91, 48, 65, 62,  1, 44, 75, 72, 67, 62])\n",
      "train_data_length       => 201617\n",
      "\n",
      "validation_data (first 10) => tensor([ 1, 77, 65, 62,  1, 76, 62, 58, 77,  1])\n",
      "validation_data_length     => 50405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"==================== Corpus =====================================\")\n",
    "print(f\"corpus_text (first 50 chars)   => {corpus_text[:50]}\")\n",
    "print(f\"corpus_text_length             => {corpus_text_length}\")\n",
    "print()\n",
    "\n",
    "print(\"==================== Vocabulary & Dictionary ====================\")\n",
    "print(f\"vocabulary (first 20) => {vocabulary[:20]}\")\n",
    "print(f\"vocabulary_length     => {vocabulary_length}\")\n",
    "print(f\"int_to_string_dictionary_length     => {int_to_string_dictionary_length}\")\n",
    "print(f\"string_to_int_dictionary_length     => {string_to_int_dictionary_length}\")\n",
    "print()\n",
    "\n",
    "print(\"==================== Tensor Data ================================\")\n",
    "print(f\"tensor_data (first 10) => {tensor_data[:10]}\")\n",
    "print(f\"tensor_data_length     => {tensor_data_length}\")\n",
    "print()\n",
    "print(f\"train_data (percentage) => {train_data_percentage*100}%\")\n",
    "print(f\"train_data (first 10)   => {train_data[:10]}\")\n",
    "print(f\"train_data_length       => {train_data_length}\")\n",
    "print()\n",
    "print(f\"validation_data (first 10) => {validation_data[:10]}\")\n",
    "print(f\"validation_data_length     => {validation_data_length}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x => tensor([91, 48, 65, 62,  1, 44, 75, 72])\n",
      "y => tensor([48, 65, 62,  1, 44, 75, 72, 67])\n",
      "\n",
      "0 => When input is tensor([91]) target is 48\n",
      "1 => When input is tensor([91, 48]) target is 65\n",
      "2 => When input is tensor([91, 48, 65]) target is 62\n",
      "3 => When input is tensor([91, 48, 65, 62]) target is 1\n",
      "4 => When input is tensor([91, 48, 65, 62,  1]) target is 44\n",
      "5 => When input is tensor([91, 48, 65, 62,  1, 44]) target is 75\n",
      "6 => When input is tensor([91, 48, 65, 62,  1, 44, 75]) target is 72\n",
      "7 => When input is tensor([91, 48, 65, 62,  1, 44, 75, 72]) target is 67\n"
     ]
    }
   ],
   "source": [
    "block_size = 8\n",
    "\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "\n",
    "print(f\"x => {x}\")\n",
    "print(f\"y => {y}\")\n",
    "print()\n",
    "\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"{t} => When input is {context} target is {target}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
